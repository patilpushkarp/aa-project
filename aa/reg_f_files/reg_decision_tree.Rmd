---
title: "Decision Tree Regression"
output:
  md_document:
    variant: gfm
---

# Decision Tree

Since the data has been cleaned, it can now be used to create the models.

```{r}
# Load libraries
library(caret)
library(rpart)
library(MASS)

# Load helpers
source("./../helpers/helper.R")
```

## Import data

To evaluate the model, there should be a set of which the model has not seen and for which the labels are known. Hence, it is necessary to split the data into training and testing set.

```{r}
# Read training and testing data
train <- read.csv("./../data/regression_data/intermediates/train.csv")
test <- read.csv("./../data/regression_data/intermediates/test.csv")
```

## Model Training

The model is first trained on the training data and then evaluated on testing data.

```{r}
# Model training
dtree.model <- rpart(CA~., data=train)
```

```{r}
summary(dtree.model)
```

## Model Validation

```{r}
# Predict the samples from test data using the model
result <- predict(dtree.model, test)

# Print the RMSE and MAE
cat(paste("RMSE: ", RMSE(result, test$CA), "\n", "MSE: ", RMSE(result, test$CA)^2, "\n", "MAE: ", MAE(result, test$CA)))
```

```{r}
# Plot feature importance
varImp.df <- data.frame(varImp(dtree.model))
varImp.df$Overall <- varImp.df[order(varImp.df$Overall, decreasing = FALSE),]
par(mar=c(15,3,3,0))
barplot(varImp.df$Overall, names.arg=rownames(varImp.df), las=2, col="blue", main="Decision Tree: Feature Importances")
```

```{r}
# Save the results
save.reg.result(RMSE(result, test$CA), MAE(result, test$CA), "Decision Tree Regression")
```

## Prediction with Unknown Data

```{r}
# Load the data
unk <- read.csv("./../data/regression_data/intermediates/unknown_data.csv")
dim(unk)

# Predict using the built model
prediction <- predict(dtree.model, unk)
prediction
```
